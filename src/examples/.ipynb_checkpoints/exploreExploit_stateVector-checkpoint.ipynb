{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Documents\\SURF 2021\\RL RNN SURF\\src\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first define the input data. The input data is has the following structure: We have a group of subjects (say S1 and S2) and each subject has completed the decision-making task multiple times (multiple blocks), say each subject has completed the task two times in this example, i.e., we have two blocks of data for each subject. The data within each block is a ditonary containing three numpy arrays: 'action', 'state', 'reward'. \n",
    "\n",
    "'action' containig the actions taken by the subject on each trial and it should be a non-zero integer or -1. If the action is -1 it will coded by a zero vector and corresponds to no-action. Dimesionlity of 'action' is B x |T| in which |T| is the number of trials.\n",
    "\n",
    "'state' contains the state of the environment each trial. Its dimesionlity is B x |T| x |S| in which |T| is the number of trials, and |S| is the lenght of state vector. \n",
    "\n",
    "'reward' contains the reward received after taking each actions. Its dimesionlity is B x |T| in which |T| is the number of trials.\n",
    "\n",
    "For example, if subject S1 has completed 6 trials in the firt block and 4 trials in the second block and subject 2 has completed 5, 6 trials in the first and second blocks respectivly, then the data structure can look like this:\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Data\n",
    "import numpy as np\n",
    "import csv\n",
    "data={}\n",
    "test_data = {}\n",
    "for i in range(1,101):\n",
    "    with open('simulationData\\sim_'+str(i)+'.csv', 'r' ) as theFile:\n",
    "        reader = csv.reader(theFile)\n",
    "        headers = next(reader, None)\n",
    "        actions = []\n",
    "        states = []\n",
    "        rewards = []\n",
    "        for line in reader:\n",
    "            actions.append(int(line[3]))\n",
    "            newState = np.zeros(13)\n",
    "            newState[int(line[8])-1] = 1\n",
    "            newState[int(line[9])-1] = 1\n",
    "            states.append(newState)\n",
    "            rewards.append(int(line[5]))\n",
    "        block = [\n",
    "                {\n",
    "                    'action': np.array([actions])-1,\n",
    "                    'state': np.array([states]),\n",
    "                    'reward': np.array([rewards]),\n",
    "                    'id': 'S'+str(i),\n",
    "\n",
    "                    'block': 0\n",
    "                }\n",
    "\n",
    "            ]\n",
    "        if i<91:\n",
    "            data['S'+str(i)] = block\n",
    "        else:\n",
    "            test_data['S'+str(i)] = block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros(13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above example, |A|=2 (there are two actions coded as 0 and 1), and |S|=2 (the state vector has two elements). For example, if there are three stimuli in the environment, they can be coded as [1, 0, 0], [0, 1, 0], [0, 0, 1] state vectors. In this case |S|=3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\documents\\surf 2021\\rl rnn surf\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\user\\documents\\surf 2021\\rl rnn surf\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\user\\documents\\surf 2021\\rl rnn surf\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\user\\documents\\surf 2021\\rl rnn surf\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\user\\documents\\surf 2021\\rl rnn surf\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\user\\documents\\surf 2021\\rl rnn surf\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "2021-07-12 12:22:08,306 - DeepRL - DEBUG - model created with ncells: 20\n",
      "2021-07-12 12:22:08,306 - DeepRL - DEBUG - number of actions: 2\n",
      "2021-07-12 12:22:08,307 - DeepRL - DEBUG - number of states: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\Documents\\SURF 2021\\RL RNN SURF\\src\\actionflow\\rnn\\lstm_base.py:14: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From c:\\users\\user\\documents\\surf 2021\\rl rnn surf\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py:423: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\User\\Documents\\SURF 2021\\RL RNN SURF\\src\\actionflow\\rnn\\lstm_base.py:43: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n"
     ]
    }
   ],
   "source": [
    "from actionflow.rnn.lstm_beh import LSTMBeh\n",
    "worker = LSTMBeh(a_size=2, s_size=2, n_cells=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-12 12:22:08,589 - DeepRL - DEBUG - version control: (None, None)\n",
      "2021-07-12 12:22:08,590 - DeepRL - DEBUG - learning rate: 0.01\n",
      "2021-07-12 12:22:08,590 - DeepRL - DEBUG - global iters: 50\n",
      "2021-07-12 12:22:08,590 - DeepRL - DEBUG - training data-points: 90\n",
      "2021-07-12 12:22:08,590 - DeepRL - DEBUG - test data-points: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\user\\documents\\surf 2021\\rl rnn surf\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-12 12:22:09,120 - DeepRL - DEBUG - opt started...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:../results/exploreExploit/model-0/model.cptk is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-12 12:22:15,416 - DeepRL - DEBUG - global iter =    0 total obj: 9986.4309\n"
     ]
    }
   ],
   "source": [
    "from actionflow.rnn.opt_beh import OptBEH\n",
    "from actionflow.util.logger import LogFile\n",
    "\n",
    "output_path = '../results/exploreExploit/'\n",
    "with LogFile(output_path, 'run.log'):\n",
    "    OptBEH.optimise(worker, output_path, data, None,\n",
    "                    learning_rate=0.01,\n",
    "                    global_iters=50,\n",
    "                    load_model_path=None\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from actionflow.data.data_process import DataProcess\n",
    "train_merged = DataProcess.merge_data(data)\n",
    "train_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then the merged data can be used for training the model as before. The test data can also be passed to the training method, in order to test the mmodel on the training data in regular intervals. Say the test data is as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and we want to test the model every 10 iterations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with LogFile(output_path, 'run.log'):\n",
    "    OptBEH.optimise(worker, output_path, data, test_data,\n",
    "                    learning_rate=0.01,\n",
    "                    global_iters=50,\n",
    "                    load_model_path=None,\n",
    "                    test_period=10\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_data[\"S100\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
